<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>NLPResource - SunsetSunrising</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=0"/>
    <link rel="stylesheet" href="/assets/style.css?v=c9d5b"/>
    <link rel="stylesheet" href="/assets/pygments.css?v=cedbb"/>
    
    <link rel="alternate" type="application/rss+xml" href="/feed.xml" title="SunsetSunrising"/>
    
<link rel="canonical" href="/2009/nlp_resource.html" />



    <script>
        (function() {
            var cx = '012347804910294994683:rsexabosj44';
            var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;
            gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
                    '//www.google.com/cse/cse.js?cx=' + cx;
            var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);
        })();
    </script>
</head>
<body>
<!--http://vimeo.com/53043267-->
<div id="topbar"></div>
<header>
    <div id="logo"><a href="/">SunsetSunrising</a></div>
    <nav id="nav" role="navigation">
        
        <a  href="/">Home</a>
        <a  href="/resume/zh.html">About</a>
    </nav>
</header>
<div id="search">
    <gcse:searchbox enableHistory="true" autoCompleteMaxCompletions="5" autoCompleteMatchType='any'></gcse:searchbox>
</div>
<div id="search-results">
    <gcse:searchresults refinementStyle="link"  adclient="pub-3716363443644786"></gcse:searchresults>
</div>
<div class="container"><h1 class="entry-title">NLPResource</h1>
<div class="entry-meta">
    <time class="updated" datetime="2009-05-22T02:05:44+08:00">
        <a href="/2009/">2009-05-22</a>
    </time>
    <span class="author vcard">
        by <a class="url fn" href="http://sunsetsunrising.com">Yan Sheng</a>
        
    </span>
</div>
<div class="entry-content">
    <p>有关NLP的资源, 主要使用的是python的nltk工具包</p>
<div class="section" id="rescource">
<h2>Rescource</h2>
<ul class="simple">
<li>Getting Started on Natural Language Processing with Python</li>
<li>Natural Language Toolkit</li>
<li>Charming Python: Get started with the Natural Language Toolkit</li>
</ul>
</div>
<div class="section" id="natural-language-processing-some-definitions">
<h2>Natural Language Processing/Some definitions</h2>
<ul class="simple">
<li>Token 分词, 这里主要指一个一个词单元</li>
<li>Sentence 有顺序的词单元序列</li>
<li>Tokenization 分词技术</li>
<li>Corpus 词集, Brown Corpus等</li>
<li>Part-of-speech(POS) tag</li>
<li>Parse tree 主要是语法解析树</li>
</ul>
</div>
<div class="section" id="the-basic-terminology">
<h2>the basic terminology</h2>
<ul class="simple">
<li>POS tagging 词性标注</li>
<li>Computational morphology is concerned with the discovery and analysis of the internal structure of words using computers.</li>
<li>Parsing: 解析器通过某复杂的统计模型自动推断出一解析树</li>
<li>Machine translation(MT): most difficult task</li>
</ul>
</div>
<div class="section" id="nltk">
<h2>NLTK介绍</h2>
<ul class="simple">
<li>Brown词集, 标准的Brown词集, 还有领域内的, 另外还有人工词性标注后的词集</li>
<li>Gutenberg词集, 大概有1.7million词.</li>
<li>Stopwords corpus, 停用词集, 包含多种语言版本</li>
</ul>
</div>
<div class="section" id="task-1-exploring-corpora">
<h2>Task 1: Exploring Corpora</h2>
<p>词集使用示例</p>
<blockquote>
<pre class="literal-block">
&gt;&gt;&gt; from nltk.corpus import gutenberg
&gt;&gt;&gt; print gutenberg.items
__main__:1: DeprecationWarning:
  Function _get_items() has been deprecated.  Use corpus.files()
  instead
('austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt')
&gt;&gt;&gt; print gutenberg.files()  ## 使用files()
('austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt')

&gt;&gt;&gt; from nltk.probability import FreqDist
&gt;&gt;&gt; fd = FreqDist()
&gt;&gt;&gt; for word in gutenberg.words(&quot;austen-persuasion.txt&quot;):  ## 原文中的raw得到的是每个字符, 每个单词应该使用words
...     fd.inc(word)
...
&gt;&gt;&gt; print fd.N()  ##　所有单词数目
98171
&gt;&gt;&gt; print fd.B()　##　唯一单词数目
6132
&gt;&gt;&gt; ss = fd.sorted()
&gt;&gt;&gt; for word in ss[:5]:
...     print word, fd[word]
...
, 6750　　　　　　　　　　　##　单词及其出现次数
the 3120
to 2775
. 2741
and 2739
</pre>
</blockquote>
<p>接下来讲了Zipf定律,,关于词频和位置的关系,,,主要是说明, 人类普遍使用的词占整个词集的少数词, 即是there are a few words that are very common, a few that occur with medium frequency, and a very large number of words that occur very rarely.</p>
<blockquote>
<pre class="literal-block">
&gt;&gt;&gt; from nltk import corpus
&gt;&gt;&gt; from nltk.probability import FreqDist
&gt;&gt;&gt; from nltk.draw.plot import Plot
&gt;&gt;&gt; fd = FreqDist()
&gt;&gt;&gt; for text in corpus.gutenberg.files():　　　## 统计词集
...     for word in corpus.gutenberg.words(text):
...         fd.inc(word)
...
&gt;&gt;&gt; ss = fd.sorted()
&gt;&gt;&gt; points = []
&gt;&gt;&gt; for index, word in enumerate(ss):
...     points.append((index+1, fd[word]))   ## 获得位置, 和频数的坐标, 即rank-frequent
...
&gt;&gt;&gt; Plot(points, scale='log').mainloop()  ## 出现了一条log-log曲线, 斜率接近于-1的直线. 是符合zipf定律中的.
</pre>
</blockquote>
</div>
<div class="section" id="task-2-predicting-words">
<h2>Task 2: Predicting Words</h2>
<p>这个例子用于预测上下文, 使用之前2, 3或多个词进行当前词的预测.</p>
<pre class="literal-block">
&gt;&gt;&gt; from nltk.corpus import gutenberg
&gt;&gt;&gt; from nltk.probability import ConditionalFreqDist
&gt;&gt;&gt; from random import choice
&gt;&gt;&gt; cfd = ConditionalFreqDist()  ## 使用的是条件频率分布
&gt;&gt;&gt; prev_word = None
&gt;&gt;&gt; for word in gutenberg.words(&quot;austen-persuasion.txt&quot;):
...     cfd[prev_word].inc(word)
...     prev_word = word
...
&gt;&gt;&gt; word = 'therefore'
&gt;&gt;&gt; i = 1
&gt;&gt;&gt; while i &lt; 20:
...     print word,
...     lwords = cfd[word].samples()  ## 随机取所有可能的
...     follower = choice(lwords)
...     word = follower
...     i += 1
...
</pre>
<p>therefore lost one of bodily weakness and present she came away some natural course ,&quot; said no flagrant open</p>
<p>这个例子只使用前一个单词, 可以使用更多的单词,,,,</p>
</div>
<div class="section" id="task-3-discovering-part-of-speech-tags">
<h2>Task 3: Discovering Part-Of-Speech Tags</h2>
<p>分析Brown词集中单词词性, Brown词集有个(token, tag)版本</p>
<pre class="literal-block">
&gt;&gt;&gt; from nltk.corpus import brown
&gt;&gt;&gt; from nltk.probability import FreqDist, ConditionalFreqDist
&gt;&gt;&gt; fd = FreqDist()
&gt;&gt;&gt; cfd = ConditionalFreqDist()
&gt;&gt;&gt; for sentence in brown.tagged_sents():  ## 获取所有句子的单词, 词性标注
...     for (token, tag) in sentence:
...         fd.inc(tag)                    ## 统计词性使用个数
...         cfd[token].inc(tag)            ## 统计某单词的词性使用个数
...
&gt;&gt;&gt; fd.max()                               ## 词性使用次数最多的
'NN'
&gt;&gt;&gt; wordbins = []
&gt;&gt;&gt; for token in cfd.conditions():         ## 获得的是(某单词的不同词性个数, 单词)列表
...     wordbins.append((cfd[token].B(), token))
...
&gt;&gt;&gt; wordbins.sort(reverse=True)
&gt;&gt;&gt; print wordbins[0]                      ## 具有最多词性种类的单词
(12, 'that')
&gt;&gt;&gt; male = ['he', 'his', 'him', 'himself']
&gt;&gt;&gt; female = ['she', 'hers', 'her', 'herself']
&gt;&gt;&gt; n_male = 0
&gt;&gt;&gt; n_female = 0
&gt;&gt;&gt; for m in male:
...     n_male += cfd[m].N()               ## 男性单词的所有个数
...
&gt;&gt;&gt; for f in female:
...     n_female += cfd[f].N()
...
&gt;&gt;&gt; print float(n_male)/n_female
3.27108476755
&gt;&gt;&gt; n_ambiguous = 0
&gt;&gt;&gt; for (ntags, token) in wordbins:       ## 具有不同种类词性的单词个数
...     if ntags &gt; 1:
...         n_ambiguous += 1
...
&gt;&gt;&gt; n_ambiguous
8729
</pre>
</div>
<div class="section" id="task-4-word-association">
<h2>Task 4: Word Association</h2>
<p>共现率(co-occurrences)来衡量单词之间的关联程度</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">brown</span><span class="p">,</span> <span class="n">stopwords</span>
<span class="kn">from</span> <span class="nn">nltk.probability</span> <span class="kn">import</span> <span class="n">FreqDist</span><span class="p">,</span> <span class="n">ConditionalFreqDist</span>
<span class="n">fd</span> <span class="o">=</span> <span class="n">FreqDist</span><span class="p">()</span>
<span class="n">cfd</span> <span class="o">=</span> <span class="n">ConditionalFreqDist</span><span class="p">()</span>
<span class="n">stopwords_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">stopwords</span><span class="o">.</span><span class="n">raw</span><span class="p">(</span><span class="s">&#39;english&#39;</span><span class="p">))</span> <span class="c">## 获取英文停用词表</span>
<span class="k">def</span> <span class="nf">is_noun</span><span class="p">(</span><span class="n">tag</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tag</span> <span class="ow">in</span> <span class="p">[</span><span class="s">&#39;NN&#39;</span><span class="p">,</span> <span class="s">&#39;NNS&#39;</span><span class="p">,</span> <span class="s">&#39;NN$&#39;</span><span class="p">,</span> <span class="s">&#39;NN-TL&#39;</span><span class="p">,</span> <span class="s">&#39;NN+BEZ&#39;</span><span class="p">,</span> <span class="s">&#39;NN+HVZ&#39;</span><span class="p">,</span> <span class="s">&#39;NNS$&#39;</span><span class="p">,</span> <span class="s">&#39;NP&#39;</span><span class="p">,</span> <span class="s">&#39;NP$&#39;</span><span class="p">,</span> <span class="s">&#39;NP+BEZ&#39;</span><span class="p">,</span> <span class="s">&#39;NPS&#39;</span><span class="p">,</span> <span class="s">&#39;NPS$&#39;</span><span class="p">,</span> <span class="s">&#39;NR&#39;</span><span class="p">,</span> <span class="s">&#39;NRS&#39;</span><span class="p">,</span> <span class="s">&#39;NR$&#39;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">brown</span><span class="o">.</span><span class="n">tagged_sents</span><span class="p">():</span>                  <span class="c">## 外层for运行时间很长</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">tagtuple</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sentence</span><span class="p">):</span>
        <span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">tag</span><span class="p">)</span> <span class="o">=</span> <span class="n">tagtuple</span>
        <span class="n">token</span> <span class="o">=</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords_list</span> <span class="ow">and</span> <span class="n">is_noun</span><span class="p">(</span><span class="n">tag</span><span class="p">):</span>
            <span class="n">window</span> <span class="o">=</span> <span class="n">sentence</span><span class="p">[</span><span class="n">index</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">index</span><span class="o">+</span><span class="mi">5</span><span class="p">]</span>         <span class="c">## 后5个单词,,,窗口</span>
            <span class="k">for</span> <span class="p">(</span><span class="n">window_token</span><span class="p">,</span> <span class="n">window_tag</span><span class="p">)</span> <span class="ow">in</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">window_token</span> <span class="o">=</span> <span class="n">window_token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">window_token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords_list</span> <span class="ow">and</span> <span class="n">is_noun</span><span class="p">(</span><span class="n">window_tag</span><span class="p">):</span>
                    <span class="n">cfd</span><span class="p">[</span><span class="n">token</span><span class="p">]</span><span class="o">.</span><span class="n">inc</span><span class="p">(</span><span class="n">window_token</span><span class="p">)</span>       <span class="c">## 增加入当前单词的相关单词</span>

<span class="k">print</span> <span class="n">cfd</span><span class="p">[</span><span class="s">&#39;bread&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  <span class="c">## cheese</span>
<span class="k">print</span> <span class="n">cfd</span><span class="p">[</span><span class="s">&#39;life&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>   <span class="c">## death</span>
<span class="k">print</span> <span class="n">cfd</span><span class="p">[</span><span class="s">&#39;road&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>   <span class="c">## block</span>
</pre></div>
<p>There are several other cutting-edge areas in NLP that currently draw a large amount of research activity. It would be informative to discuss a few of them here:</p>
<blockquote>
<ul class="simple">
<li>Syntax-based machine translation: For the past decade or so, most of the research in machine translation has focused on using statistical methods on very large corpora to learn translations of words and phrases. However, more and more researchers are starting to incorporate syntax into such methods [10].</li>
<li>Automatic multi-document text summarization: There are a large number of efforts underway to use computers to automatically generate coherent and informative summaries for a cluster of related documents [8]. This task is considerably more difficult compared to generating a summary for a single document, because there may be redundant information present across multiple documents.</li>
<li>Computational parsing: Although the problem of using probabilistic models to automatically generate syntactic structures for a given input text has been around for a long time, there are still significant improvements to be made. The most challenging task is to be able to parse, with reasonable accuracy, languages that exhibit very different linguistic properties when compared to English, such as Chinese and Arabic [7].</li>
</ul>
</blockquote>
</div>
<div class="section" id="tokenization">
<h2>Tokenization</h2>
<pre class="literal-block">
&gt;&gt;&gt; from nltk.tokenize import WordTokenizer
&gt;&gt;&gt; WordTokenizer().tokenize(&quot;She said 'hello'.&quot;)
</pre>
<p>这里有很多Tokenizer类</p>
</div>
<div class="section" id="probability">
<h2>Probability</h2>
<p>主要是使用FreqDist()和ConditionalFreqDist()</p>
</div>
<div class="section" id="stemming">
<h2>stemming</h2>
<p>提取词干</p>
<pre class="literal-block">
&gt;&gt;&gt; from nltk.stem.porter import PorterStemmer
&gt;&gt;&gt; PorterStemmer().stem_word(&quot;his&quot;)
'hi'
</pre>
<p>可以看到有时候提取的词干并不对, 可以使用snallbow或者其他的, 好像之前研究wordnet时也有涉及</p>
</div>
<div class="section" id="tagging-chunking-and-parsing">
<h2>Tagging, chunking and parsing</h2>
<p>tag, 标注
chunk,  这边好几个函数使用还没懂</p>
</div>

</div>
<div class="entry-tags">
    <a href="/tag/#Python">Python</a><a href="/tag/#Datamining">Datamining</a>
</div>


<div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_shortname = 'sunsetsunrising';
    var disqus_title = 'NLPResource';
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'http://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
</div>
<footer>
    <hr class="end"/>
    <p>&copy;2008~2012  <a href="https://github.com/lizzie/lizzie.github.com">Liz</a> </p>
</footer>

<script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-4419044-5']);
    _gaq.push(['_trackPageview']);
    _gaq.push(['_trackPageLoadTime']);
    (function () {
        var ga = document.createElement('script');
        ga.type = 'text/javascript';
        ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(ga, s);
    })();
</script>
</body>
</html>